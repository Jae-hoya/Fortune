{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c14a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee222e",
   "metadata": {},
   "source": [
    "```python\n",
    "LANGCHAIN_TRACING_V2=True  # 켜면 모든 실행 기록을 LangSmith에 보냄\n",
    "LANGCHAIN_TRACING_V2=False # 끄면 추적 안 함 (에러 없음)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39038ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Cache_FAISS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"Cache_FAISS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea3614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Markdown 파일 경로\n",
    "FILE_PATH = \"../ParsingData/LlamaParse_Multimodal(gpt-4o-mini).md\"\n",
    "\n",
    "# TextLoader로 불러오기\n",
    "loader = TextLoader(FILE_PATH, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896c5334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(docs)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48bd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_17228\\3541954798.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 벡터 저장소로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(documents, embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b70e18",
   "metadata": {},
   "source": [
    "### 임베딩 & 벡터 DB 에 저장\n",
    "\n",
    "캐시형 임베딩을 사용해, 이전에 계산된 임베딩을 캐시에서 불러오는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd41abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import LocalFileStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 로컬파일 저장소 설정\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# 캐시를 지원하는 임베딩 생성\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embeddings,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=embeddings.model # 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩을 생성\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e1f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS_DB_PATH = \"cache\"\n",
    "db.save_local(FAISS_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f2cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# allow_dangerous_deserialization: Pickle을 통한 위험한 객체 로드를 허용. 악성 코드가 실행될 가능성 있음\n",
    "vectorstore = FAISS.load_local(\n",
    "    FAISS_DB_PATH, embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630a3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab9bab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9e19f8fb-badb-46e0-93f9-f3cccc3ff445', metadata={'source': '../ParsingData/LlamaParse_Multimodal(gpt-4o-mini).md'}, page_content='삼성 가우스는 스텍스트를 생성하는 언어모델 스코드를 생성하는 코드 모델 스미지를 생성하는 이미지 모델의 3개 모델로 구성\\n\\n| 모델     | 설명                                                                |\\n| ------ | ----------------------------------------------------------------- |\\n| 언어 모델  | 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 이메일 작성, 문서 요약, 번역 업무 처리 지원           |\\n| 코드 모델  | AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 사내 소프트웨어 개발에 최적화 |\\n| 이미지 모델 | 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 저해상도 이미지의 고해상도 전환도 지원 |\\n\\nIT 전문 매체 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했으며, 2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)를 탑재한 웨얼러 기기 구글 어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n\\n출처: 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성 AI ‘삼성 가우스’ 공개, 2023.11.08\\n\\n삼성전자, ‘삼성 개발자 컨퍼런스 코리아 2023’ 개최, 2023.11.14.\\n\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n\\n# 구글, 앤스프릭에 최대 20억 달러 투자로 생성 AI 협력 강화\\n\\n# KEY Contents'),\n",
       " Document(id='378c2748-4973-4997-9af5-83aa6be40788', metadata={'source': '../ParsingData/LlamaParse_Multimodal(gpt-4o-mini).md'}, page_content='# 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\n\\n# KEY Contents\\n\\n- 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 AI 모델 ‘삼성 가우스’를 공개\\n- 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n\\n# 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\n\\n삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 ‘삼성 가우스’를 최초 공개\\n\\n정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본딴 삼성 가우스는 다양한 상황에 최적화된 크기의 모델 선택이 가능\\n\\n삼성 가우스는 라이센스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, 온디바이스에서 작동하도록 설계되어 외부로 사용자 정보가 유출되지 않는 장점을 보유\\n\\n삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 단계적으로 탑재할 계획\\n\\n삼성 가우스는 스텍스트를 생성하는 언어모델 스코드를 생성하는 코드 모델 스미지를 생성하는 이미지 모델의 3개 모델로 구성'),\n",
       " Document(id='02ecf20e-0a9d-4fae-9bf6-4f2744a617ab', metadata={'source': '../ParsingData/LlamaParse_Multimodal(gpt-4o-mini).md'}, page_content=\"| 2. 기업/산업                                                                                                                                                                                                                                                                                           |\\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| * 미국 포트레이터 모델 포럼, 1,000달러 규모의 AI 안전 기금 조성\\n* 코어AI, 데이터 두뇌화 확대를 위한 데이터 출처 탐색기 공개\\n* 알리바바 클라우드, 최신 LLM '동이거인 2.0' 공개\\n* 삼성전자, 자체 개발 생산 신 '삼성 가우스' 공개\\n* 구글, 앤스프리트 20억 달러 투자를 생산 AI 협력 강화\\n* IDC, 2027년 시 소프트웨어 매출 2,500억 달러 돌파 전망\\n* 빌 게이츠, AI 에이전트를 통한 컴퓨터 사용의 패러다임 변화 전망\\n* 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화 |\"),\n",
       " Document(id='435855aa-2b74-4782-901d-b03d2622e83c', metadata={'source': '../ParsingData/LlamaParse_Multimodal(gpt-4o-mini).md'}, page_content='중국의 알리바바 클라우드가 2023년 10월 31일 열린 연례 기술 컨퍼런스에서 최신 LLM ‘통이치엔원(Tongyi Qianwen) 2.0’을 공개\\n\\n- 알리바바 클라우드는 통이치엔원 2.0이 2023년 4월 출시된 1.0 버전보다 복잡한 지칭 이해, 광고문구 작성, 추론, 감기 등에 성능이 향상되었다고 설명\\n- 통이치엔원 2.0은 여러 테스트(MMLU), 수학(GSM8), 질문 답변(ARC-C)과 같은 벤치마크 테스트에서 Llama-2-70B와 GPT-3.5를 비롯한 여러 AI 모델을 능가\\n- 통이치엔원 2.0 알리바바 클라우드의 웹앱과 모바일 앱을 통해 대중에게 제공되며 개발자는 API를 통해 사용 가능\\n\\n# 알리바바 클라우드는 여러 산업 영역에서 생성 AI를 활용해 사업 성과를 개선할 수 있도록 지원하는 산업별 모델도 출시\\n\\n- 산업 영역은 교육지원, 법률 상담, 의료, 금융, 문서관리, 오디오와 동영상 관리, 코드 개발, 캐릭터 제작을 포함\\n\\n# 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를 간소화하는 원인인 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’도 공개\\n\\n- 이 플랫폼은 데이터 관리, 모델 배포 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여 다양한 기업들이 맞춤형 AI 모델을 쉽게 개발할 수 있도록 지원\\n- 생성 AI 개발에 필요한 컴퓨터 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI), 데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드로 신제품도 발출\\n\\n# 알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720여 개 매개변수를 가진 통이치엔원 모델을 오픈소스화할 계획도 공개\\n\\n# 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\n\\n# KEY Contents')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"삼성전자 생성형 ai의름은?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
