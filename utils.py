"""
FortuneAI ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
UI, ì¿¼ë¦¬ ì²˜ë¦¬, ë””ìŠ¤í”Œë ˆì´ ê´€ë ¨ ëª¨ë“  ê¸°ëŠ¥ í†µí•©
"""

import os
import sys
import time
from datetime import datetime
from langchain_core.messages import HumanMessage, AIMessage


# ================================
# UI / ë””ìŠ¤í”Œë ˆì´ ê´€ë ¨ í•¨ìˆ˜ë“¤
# ================================

def print_banner():
    """ì‹œìŠ¤í…œ ë°°ë„ˆ ì¶œë ¥"""
    print("=" * 70)
    print("ğŸ”® FortuneAI - LangGraph ì‚¬ì£¼ ì‹œìŠ¤í…œ ğŸ”®")
    print("=" * 70)
    print("âœ¨ Supervisor íŒ¨í„´ ê¸°ë°˜ ê³ ì„±ëŠ¥ ì‚¬ì£¼ ê³„ì‚°ê¸°")
    print("ğŸ¯ 98ì  ì „ë¬¸ê°€ ê²€ì¦ ì™„ë£Œ")
    print("ğŸš€ LangGraph ë©€í‹° ì›Œì»¤ ì‹œìŠ¤í…œ")
    print("-" * 70)
    print("ğŸ—ï¸  ì‹œìŠ¤í…œ êµ¬ì¡°:")
    print("  â€¢ Supervisor â†’ SajuExpert(manse + retriever) / WebTool / GeneralQA")
    print("  â€¢ ì‚¬ì£¼ê³„ì‚°: calculate_saju_tool")
    print("  â€¢ RAGê²€ìƒ‰: saju_retriever_tool") 
    print("  â€¢ ì›¹ê²€ìƒ‰: tavily_tool, duck_tool")
    print("  â€¢ ì¼ë°˜QA: general_qa_tool (Google Gemini)")
    print("-" * 70)
    print("ğŸ“ ì‚¬ìš©ë²•:")
    print("  â€¢ ì‚¬ì£¼ ê³„ì‚°: '1995ë…„ 8ì›” 26ì¼ ì˜¤ì „ 10ì‹œ 15ë¶„ ë‚¨ì ì‚¬ì£¼'")
    print("  â€¢ ìš´ì„¸ ìƒë‹´: '1995ë…„ 8ì›” 26ì¼ìƒ 2024ë…„ ì—°ì• ìš´'")
    print("  â€¢ ì¼ë°˜ ê²€ìƒ‰: 'ì‚¬ì£¼ì—ì„œ ì‹­ì‹ ì´ë€?'")
    print("  â€¢ ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit'")
    print("  â€¢ ë””ë²„ê·¸: '--debug' ë˜ëŠ” 'debug:ì§ˆë¬¸' (ìƒì„¸ ê°œë°œì ëª¨ë“œ)")
    print("=" * 70)


def print_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
    print("\nğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
    print(f"  â€¢ ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  â€¢ Python ë²„ì „: {sys.version.split()[0]}")
    print(f"  â€¢ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
    print(f"  â€¢ ì›Œì»¤ ë…¸ë“œ: Supervisor, SajuExpert(manse+retriever), WebTool, GeneralQA")
    print(f"  â€¢ ëª¨ë“œ: ê¸°ë³¸(ì£¼ìš” ë…¸ë“œë§Œ) / ë””ë²„ê·¸(ì „ì²´ ë…¸ë“œ + ì„±ëŠ¥ ë¶„ì„)")
    print()


def format_response(response: str) -> str:
    """ì‘ë‹µ í¬ë§·íŒ…"""
    if not response:
        return "âŒ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì‘ë‹µ ì•ì— êµ¬ë¶„ì„  ì¶”ê°€
    formatted = "\n" + "ğŸ¯ " + "=" * 55 + "\n"
    formatted += "ğŸ“‹ **FortuneAI ë¶„ì„ ê²°ê³¼**\n"
    formatted += "=" * 58 + "\n\n"
    formatted += response
    formatted += "\n\n" + "=" * 58
    
    return formatted


def print_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    print("""
ğŸ“š **FortuneAI ì‚¬ìš© ê°€ì´ë“œ**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”® **ì‚¬ì£¼ ê³„ì‚°**: '1995ë…„ 8ì›” 26ì¼ ì˜¤ì „ 10ì‹œ 15ë¶„ ë‚¨ì ì‚¬ì£¼'
ğŸ“– **ì‚¬ì£¼ í•´ì„**: 'ì‚¬ì£¼ì—ì„œ ì‹­ì‹ ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?'
ğŸŒ **ì¼ë°˜ ì§ˆë¬¸**: '2024ë…„ ê°‘ì§„ë…„ì˜ íŠ¹ì§•ì€?'

ğŸ› ï¸  **ëª…ë ¹ì–´**:
  â€¢ new, clear      : ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
  â€¢ help, ?         : ë„ì›€ë§ ë³´ê¸°
  â€¢ quit, exit      : í”„ë¡œê·¸ë¨ ì¢…ë£Œ
  â€¢ debug:ì§ˆë¬¸      : ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰

ğŸ—ï¸  **ì›Œí¬í”Œë¡œ êµ¬ì¡°**:
  1. Supervisor: ì§ˆë¬¸ ë¶„ì„ í›„ ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…
  2. SajuExpert: ì‚¬ì£¼ ê´€ë ¨ â†’ manse(ê³„ì‚°) + retriever(RAGê²€ìƒ‰)
  3. WebTool: ì¼ë°˜ ì‚¬ì£¼ ê°œë… â†’ tavily_tool, duck_tool
  4. GeneralQA: ë¹„ì‚¬ì£¼ ì§ˆë¬¸ â†’ general_qa_tool (Google Gemini)

ğŸ¯ **ëª¨ë“œ ì„¤ëª…**:
  â€¢ ê¸°ë³¸ ëª¨ë“œ: ì£¼ìš” ì‘ì—… ë…¸ë“œë§Œ ê¹”ë”í•˜ê²Œ í‘œì‹œ (ì‚¬ìš©ì ì¹œí™”ì )
  â€¢ ë””ë²„ê·¸ ëª¨ë“œ: ëª¨ë“  ë…¸ë“œ + ì„±ëŠ¥ ë¶„ì„ (ê°œë°œììš©)

ğŸ”§ **ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´**:
  â€¢ calculate_saju_tool: ì‚¬ì£¼íŒ”ì ê³„ì‚°
  â€¢ saju_retriever_tool: ì‚¬ì£¼ ì§€ì‹ ë²¡í„°DB ê²€ìƒ‰
  â€¢ tavily_tool, duck_tool: ì›¹ ê²€ìƒ‰
  â€¢ general_qa_tool: Google Gemini ê¸°ë°˜ ì¼ë°˜ QA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """)


def print_node_header(node_name: str, is_debug: bool = False):
    """ë…¸ë“œ í—¤ë” ì¶œë ¥ - ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥´ê²Œ í‘œì‹œ"""
    if is_debug:
        # ë””ë²„ê·¸ ëª¨ë“œ: ìƒì„¸í•œ ì„¤ëª…
        print("\n" + "=" * 60)
        
        node_descriptions = {
            "Supervisor": "ğŸ¯ ì›Œí¬í”Œë¡œ ê´€ë¦¬ì - ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…",
            "SajuExpert": "ğŸ”® ì‚¬ì£¼ ì „ë¬¸ê°€ - ë§Œì„¸ë ¥ ê³„ì‚° + RAG ê²€ìƒ‰",
            "manse": "ğŸ“… ë§Œì„¸ë ¥ ê³„ì‚°ê¸° - ì‚¬ì£¼íŒ”ì ê³„ì‚° íˆ´ ì‚¬ìš©",
            "retriever": "ğŸ” RAG ê²€ìƒ‰ê¸° - ì‚¬ì£¼ ì§€ì‹ ë²¡í„°DB ê²€ìƒ‰",
            "WebTool": "ğŸŒ ì›¹ ê²€ìƒ‰ê¸° - Tavily/DuckDuckGo ê²€ìƒ‰ íˆ´ ì‚¬ìš©",
            "GeneralQA": "ğŸ’¬ ì¼ë°˜ QA - Google Gemini ëª¨ë¸ ì‚¬ìš©"
        }
        
        description = node_descriptions.get(node_name, "ğŸ”§ ì‹œìŠ¤í…œ ë…¸ë“œ")
        print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m")
        print(f"ğŸ“ {description}")
        print("- " * 30)
    else:
        # ê¸°ë³¸ ëª¨ë“œ: ê°„ë‹¨í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° ì¹œí™”ì 
        node_info = {
            "SajuExpert": ("ğŸ”®", "ì‚¬ì£¼ ì „ë¬¸ê°€"),
            "manse": ("ğŸ“…", "ë§Œì„¸ë ¥ ê³„ì‚°"),
            "retriever": ("ğŸ”", "ì§€ì‹ ê²€ìƒ‰"), 
            "WebTool": ("ğŸŒ", "ì›¹ ê²€ìƒ‰"),
            "GeneralQA": ("ğŸ’¬", "ì¼ë°˜ ìƒë‹´")
        }
        
        icon, name = node_info.get(node_name, ("ğŸ”§", node_name))
        print(f"\n{icon} {name} ì‹¤ì‹œê°„ ì‘ë‹µ:")
        print("â”€" * 30)


def print_simple_node_info(node_name: str):
    """ê¸°ë³¸ ëª¨ë“œ: ê°„ë‹¨í•œ ë…¸ë“œ ì •ë³´ í‘œì‹œ"""
    node_info = {
        "SajuExpert": "ğŸ”® ì‚¬ì£¼ ì „ë¬¸ê°€",
        "manse": "ğŸ“… ë§Œì„¸ë ¥ ê³„ì‚°", 
        "retriever": "ğŸ” ì§€ì‹ ê²€ìƒ‰",
        "WebTool": "ğŸŒ ì›¹ ê²€ìƒ‰",
        "GeneralQA": "ğŸ’¬ ì¼ë°˜ ìƒë‹´"
    }
    
    info = node_info.get(node_name, f"ğŸ”§ {node_name}")
    print(f"\n{info} ì¤‘...")


def print_node_execution(node_name: str):
    """ë””ë²„ê·¸ ëª¨ë“œ: ìƒì„¸í•œ ë…¸ë“œ ì‹¤í–‰ ì •ë³´ì™€ ì‚¬ìš© íˆ´ í‘œì‹œ"""
    node_tool_info = {
        "Supervisor": ("ğŸ¯", "ë¼ìš°íŒ…", "ì›Œí¬í”Œë¡œ ê´€ë¦¬"),
        "SajuExpert": ("ğŸ”®", "ì‚¬ì£¼ë¶„ì„", "manse + retriever ì„œë¸Œê·¸ë˜í”„"),
        "manse": ("ğŸ“…", "ë§Œì„¸ë ¥ê³„ì‚°", "calculate_saju_tool"),
        "retriever": ("ğŸ”", "ì§€ì‹ê²€ìƒ‰", "saju_retriever_tool"),
        "WebTool": ("ğŸŒ", "ì›¹ê²€ìƒ‰", "tavily_tool + duck_tool"),
        "GeneralQA": ("ğŸ’¬", "ì¼ë°˜ìƒë‹´", "general_qa_tool (Google Gemini)")
    }
    
    icon, action, tools = node_tool_info.get(node_name, ("ğŸ”§", node_name, "unknown"))
    
    print(f"\n{icon} {action} ë…¸ë“œ ì‹¤í–‰")
    print(f"  ğŸ› ï¸  ì‚¬ìš© íˆ´: {tools}")
    print("â”€" * 40)


def print_completion(is_debug: bool = False):
    """ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥"""
    if is_debug:
        print("\n" + "=" * 60)
        print("âœ… ë””ë²„ê·¸ ëª¨ë“œ ì™„ë£Œ! (ì „ì²´ ì›Œí¬í”Œë¡œ + ì„±ëŠ¥ ë¶„ì„)")
        print("ğŸ“Š ëª¨ë“  ë…¸ë“œì˜ ìƒì„¸ ì •ë³´ê°€ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤")
        print("=" * 60)
    else:
        print("\n" + "â”€" * 30)
        print("âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ!")
        print("â•" * 40)


# ================================
# ì¿¼ë¦¬ ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤
# ================================

def handle_debug_query(query: str, app, conversation_history: list) -> str:
    """ë””ë²„ê·¸ ì¿¼ë¦¬ ì²˜ë¦¬"""
    if not query.startswith("debug:"):
        return None
    
    actual_query = query[6:].strip()
    if not actual_query:
        return "âŒ ë””ë²„ê·¸í•  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: debug:1995ë…„ 8ì›” 26ì¼ ì‚¬ì£¼"
    
    print(f"\nğŸ” ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘: '{actual_query}'")
    print("-" * 50)
    
    start_time = time.time()
    response = run_query_with_debug(actual_query, app, conversation_history)
    execution_time = time.time() - start_time
    
    debug_info = f"""
ğŸ” **ë””ë²„ê·¸ ë¶„ì„ ê²°ê³¼**
â€¢ ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ
â€¢ ì§ˆë¬¸: {actual_query}
â€¢ ë…¸ë“œ ê²½ë¡œ: Supervisor â†’ ì „ë¬¸ ì—ì´ì „íŠ¸ â†’ ì‘ë‹µ ìƒì„±

ğŸ“‹ **ìµœì¢… ì‘ë‹µ**
{response}

âš¡ **ì„±ëŠ¥ ì •ë³´**
â€¢ ì´ ì²˜ë¦¬ ì‹œê°„: {execution_time:.2f}ì´ˆ
â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©: ì²´í¬í¬ì¸í„° í™œìš©í•œ ìƒíƒœ ê´€ë¦¬
"""
    return debug_info


def run_query_with_app(query: str, app, conversation_history: list) -> str:
    """ê¸°ë³¸ ëª¨ë“œ: í–¥ìƒëœ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©"""
    # í–¥ìƒëœ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
    return run_query_with_streaming(query, app, conversation_history)


def get_node_tools(node_name: str) -> str:
    """ë…¸ë“œë³„ ì‚¬ìš© íˆ´ ë°˜í™˜"""
    node_tools = {
        "Supervisor": "ì›Œí¬í”Œë¡œ ê´€ë¦¬",
        "SajuExpert": "manse + retriever ì„œë¸Œê·¸ë˜í”„",
        "manse": "calculate_saju_tool",
        "retriever": "saju_retriever_tool",
        "WebTool": "tavily_tool + duck_tool",
        "GeneralQA": "general_qa_tool (Google Gemini)"
    }
    return node_tools.get(node_name, "unknown")


def run_query_with_streaming(query: str, app, conversation_history: list) -> str:
    """ê¸°ë³¸ ëª¨ë“œ: ê¹”ë”í•œ ìŠ¤íŠ¸ë¦¬ë° (ì£¼ìš” ë…¸ë“œë§Œ)"""
    print(f"ğŸ” ì¿¼ë¦¬ ì‹¤í–‰: {query}")
    
    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    conversation_history.append(HumanMessage(content=query))
    
    current_state = {
        "messages": conversation_history.copy(),
        "next": ""
    }
    
    # ì„¤ì • ìƒì„± (Checkpointerìš©)
    config = {
        "configurable": {
            "thread_id": f"thread_{int(time.time())}"
        }
    }
    
    try:
        print("ğŸš€ AI ë¶„ì„ ì‹œì‘...")
        
        # ê¸°ë³¸ ëª¨ë“œ: ì£¼ìš” ì‘ì—… ë…¸ë“œë§Œ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
        final_response = ""
        prev_node = ""
        node_sequence = []
        displayed_content = []
        
        # ì£¼ìš” ì‘ì—… ë…¸ë“œë§Œ í•„í„°ë§ (SupervisorëŠ” ì œì™¸)
        work_nodes = ["SajuExpert", "manse", "retriever", "WebTool", "GeneralQA"]
        
        for chunk_msg, metadata in app.stream(current_state, config=config, stream_mode="messages"):
            curr_node = metadata.get("langgraph_node", "")
            
            # ì£¼ìš” ì‘ì—… ë…¸ë“œë§Œ í‘œì‹œ
            if curr_node in work_nodes and curr_node != prev_node:
                print_simple_node_info(curr_node)
                node_sequence.append(curr_node)
                prev_node = curr_node
            
            # í† í°ë³„ë¡œ ì‹¤ì‹œê°„ ì¶œë ¥
            if chunk_msg.content:
                print(chunk_msg.content, end="", flush=True)
                displayed_content.append(chunk_msg.content)
        
        # ê°„ë‹¨í•œ ì™„ë£Œ ì •ë³´
        print(f"\n\nâœ… ì™„ë£Œ! (ê²½ë¡œ: {' â†’ '.join(node_sequence)})")
        
        # ìµœì¢… ì‘ë‹µ íšë“
        if displayed_content:
            final_response = "".join(displayed_content)
            conversation_history.append(AIMessage(content=final_response))
            return final_response
        else:
            print("âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨")
            return "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def run_query_with_debug(query: str, app, conversation_history: list) -> str:
    """ë””ë²„ê·¸ ëª¨ë“œ: ëª¨ë“  ë…¸ë“œ + ìƒì„¸ ì •ë³´ + íˆ´ ì¶”ì """
    print(f"ğŸ” ì¿¼ë¦¬ ì‹¤í–‰ (ë””ë²„ê·¸): {query}")
    
    # ìƒˆë¡œìš´ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    conversation_history.append(HumanMessage(content=query))
    
    # í˜„ì¬ ìƒíƒœ ì„¤ì •
    current_state = {
        "messages": conversation_history.copy(),
        "next": ""
    }
    
    # ì„¤ì • ìƒì„± (Checkpointerìš©)
    config = {
        "configurable": {
            "thread_id": f"thread_{int(time.time())}"
        }
    }
    
    try:
        print("ğŸš€ ì›Œí¬í”Œë¡œ ì‹¤í–‰ ì¤‘ (ì „ì²´ ë…¸ë“œ + íˆ´ ì¶”ì )...")
        
        # ë””ë²„ê·¸ ëª¨ë“œ: ëª¨ë“  ë…¸ë“œì™€ ìƒì„¸ ì •ë³´ í‘œì‹œ
        final_response = ""
        prev_node = ""
        displayed_content = []
        node_sequence = []
        tool_usage = {}  # ë…¸ë“œë³„ íˆ´ ì‚¬ìš© ê¸°ë¡
        
        for chunk_msg, metadata in app.stream(current_state, config=config, stream_mode="messages"):
            curr_node = metadata.get("langgraph_node", "")
            
            # ìƒˆë¡œìš´ ë…¸ë“œ ì§„ì… ì‹œ ìƒì„¸ ì •ë³´ ì¶œë ¥
            if curr_node and curr_node != prev_node:
                print_node_header(curr_node, is_debug=True)
                print_node_execution(curr_node)  # íˆ´ ì •ë³´ë„ í•¨ê»˜ ì¶œë ¥
                node_sequence.append(curr_node)
                tool_usage[curr_node] = get_node_tools(curr_node)
                print("ğŸ’¬ ìƒì„¸ ì‘ë‹µ:")
                prev_node = curr_node
            
            # í† í°ë³„ë¡œ ì‹¤ì‹œê°„ ì¶œë ¥
            if chunk_msg.content:
                print(chunk_msg.content, end="", flush=True)
                displayed_content.append(chunk_msg.content)
        
        # ë””ë²„ê·¸ ì •ë³´ ìš”ì•½
        print(f"\n\nğŸ“Š ì›Œí¬í”Œë¡œ ë¶„ì„ ê²°ê³¼:")
        print(f"ğŸ¯ ì‹¤í–‰ëœ ë…¸ë“œ: {' â†’ '.join(node_sequence)}")
        print(f"ğŸ› ï¸  ì‚¬ìš©ëœ íˆ´:")
        for node, tools in tool_usage.items():
            print(f"   â€¢ {node}: {tools}")
        
        print_completion(is_debug=True)
        
        # ìµœì¢… ì‘ë‹µ íšë“
        if displayed_content:
            final_response = "".join(displayed_content)
        else:
            result = app.invoke(current_state, config=config)
            messages = result.get("messages", [])
            if messages:
                final_response = messages[-1].content
            else:
                final_response = "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        conversation_history.append(AIMessage(content=final_response))
        return final_response
            
    except Exception as e:
        print(f"âŒ ë””ë²„ê·¸ ëª¨ë“œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}" 