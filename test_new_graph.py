"""
ìƒˆë¡œìš´ LangGraph êµ¬ì¡° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - í†µí•©ëœ nodes.py ì‚¬ìš©
"""

from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph_system.graph import create_workflow

def test_new_graph():
    """ìƒˆë¡œìš´ ê·¸ë˜í”„ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    print("  - NodeManager ì´ˆê¸°í™”...")
    print("  - SajuExpert ì„œë¸Œê·¸ë˜í”„ ìƒì„±...")
    print("  - ë…¸ë“œë“¤ í†µí•© ë¡œë”©...")
    
    try:
        # ì›Œí¬í”Œë¡œ ìƒì„±
        app = create_workflow()
        print("âœ… ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_query = "1995ë…„ 3ì›” 28ì¼ ë‚¨ì, 12ì‹œ 30ë¶„ ì¶œìƒ ìš´ì„¸ë´ì¤˜"
        
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_query}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [HumanMessage(content=test_query)],
            "next": ""
        }
        
        # ì„¤ì • ìƒì„±
        config = RunnableConfig(
            recursion_limit=20, 
            configurable={"thread_id": "test_123"}
        )
        
        print("ğŸš€ ì‹¤í–‰ ì¤‘...")
        print("  - Supervisor ì‹œì‘...")
        print("  - SajuExpert ì„œë¸Œê·¸ë˜í”„ ì‹¤í–‰...")
        print("  - Manse -> Retriever ìˆœì°¨ ì²˜ë¦¬...")
        
        result = app.invoke(initial_state, config=config)
        
        # ê²°ê³¼ í™•ì¸
        messages = result.get("messages", [])
        if messages:
            print(f"\nâœ… ì„±ê³µ! ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
            print(f"ğŸ“‹ ìµœì¢… ì‘ë‹µ:\n{messages[-1].content}")
        else:
            print("âŒ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_new_graph() 