import os
import pandas as pd
from typing import List
from langchain_core.documents import Document
from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import ast

# CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
CARD_CSV_PATH = "parsed_chunks/tarot_card_chunk.csv"  # ì¹´ë“œ ë°ì´í„°
SPREAD_CSV_PATH = "parsed_chunks/tarot_spread_chunk.csv"  # ìŠ¤í”„ë ˆë“œ ë°ì´í„°

def parse_positions(positions_raw):
    """
    positions ì»¬ëŸ¼ì—ì„œ í¬ì§€ì…˜ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
    - íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸(dictì˜ ë¦¬ìŠ¤íŠ¸) ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±
    """
    if not positions_raw or not isinstance(positions_raw, str):
        return []
    try:
        positions = ast.literal_eval(positions_raw)
        if isinstance(positions, list):
            return positions
    except Exception:
        pass
    return []

def load_csv_to_documents(csv_path: str) -> List[Document]:
    """CSV íŒŒì¼ì„ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ - ë©”íƒ€ë°ì´í„° í¬í•¨ ì„ë² ë”©"""
    print(f"ğŸ“„ CSV íŒŒì¼ ë¡œë“œ ì¤‘: {csv_path}")
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []
    
    documents = []
    
    for idx, row in df.iterrows():
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "id": row.get("id", f"doc_{idx}"),
            "source": row.get("source", "unknown"),
            "chapter": row.get("chapter", ""),
            "content_type": row.get("content_type", ""),
            "word_count": row.get("word_count", 0)
        }
        
        # í˜ì´ì§€ ì½˜í…ì¸  êµ¬ì„± (ë©”íƒ€ë°ì´í„° í¬í•¨)
        page_content_parts = []
        
        # ì¹´ë“œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if pd.notna(row.get("card_name")) and row.get("card_name"):
            card_name = row["card_name"]
            card_type = row.get("card_type", "")
            orientation = row.get("orientation", "")
            
            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
            metadata["card_name"] = card_name
            metadata["card_type"] = card_type
            metadata["orientation"] = orientation
            
            # ì¶”ê°€ ì¹´ë“œ ë©”íƒ€ë°ì´í„°
            if card_type == "major_arcana":
                metadata["is_major_arcana"] = True
                
                # Tarot-for-beginners ì†ŒìŠ¤ì—ì„œ ì¶”ê°€ ë©”íƒ€ë°ì´í„° íŒŒì‹±
                if metadata["source"] == "Tarot-for-beginners":
                    content = row.get("content", "")
                    if content:
                        # ëŒ€ì²´ ì´ë¦„ ì¶”ì¶œ
                        also_known_as = extract_also_known_as(content)
                        if also_known_as:
                            metadata["also_known_as"] = also_known_as
                            page_content_parts.append(f"ALSO KNOWN AS: {', '.join(also_known_as)}")
                            
                        # ìš”ì†Œ ì¶”ì¶œ
                        element = extract_element(content)
                        if element:
                            metadata["element"] = element
                            page_content_parts.append(f"ELEMENT: {element}")
                            
                        # ë³„ìë¦¬ ì¶”ì¶œ
                        astrology = extract_astrology(content)
                        if astrology:
                            metadata["astrology"] = astrology
                            page_content_parts.append(f"ASTROLOGY: {astrology}")
                            
                        # ìˆ«ìí•™ ì¶”ì¶œ
                        numerology = extract_numerology(content)
                        if numerology:
                            metadata["numerology"] = numerology
                            page_content_parts.append(f"NUMEROLOGY: {numerology}")
                            
                        # í‚¤ì›Œë“œ ì¶”ì¶œ (KEYWORDS ì„¹ì…˜ì—ì„œ)
                        keywords = extract_tarot_keywords(content)
                        if keywords:
                            metadata["tarot_keywords"] = keywords
                            page_content_parts.append(f"TAROT KEYWORDS: {', '.join(keywords)}")
                            
                        # ì‹ í™”ì  ì—°ê´€ ì¶”ì¶œ
                        mythological_association = extract_mythological_association(content)
                        if mythological_association:
                            metadata["mythological_association"] = mythological_association
                            page_content_parts.append(f"MYTHOLOGICAL ASSOCIATION: {mythological_association}")
                            
                        # ìƒì§• ì¶”ì¶œ
                        symbols = extract_symbols(content)
                        if symbols:
                            metadata["symbols"] = symbols
                            page_content_parts.append(f"SYMBOLS: {', '.join(symbols)}")
                            
                        # ê´€ë ¨ ì¹´ë“œ ì¶”ì¶œ
                        related_cards = extract_related_cards(content)
                        if related_cards:
                            if related_cards.get("supporting_cards"):
                                metadata["supporting_cards"] = related_cards["supporting_cards"]
                                page_content_parts.append(f"SUPPORTING CARDS: {', '.join(related_cards['supporting_cards'])}")
                            if related_cards.get("opposing_cards"):
                                metadata["opposing_cards"] = related_cards["opposing_cards"]
                                page_content_parts.append(f"OPPOSING CARDS: {', '.join(related_cards['opposing_cards'])}")
                
            elif card_type == "minor_arcana":
                metadata["is_minor_arcana"] = True
                
                # ì¹´ë“œ ìŠˆíŠ¸(ë¬¸ì–‘) ì¶”ì¶œ (Cups, Wands, Pentacles, Swords)
                for suit in ["Cups", "Wands", "Pentacles", "Swords"]:
                    if suit.lower() in card_name.lower():
                        metadata["suit"] = suit
                        break
                        
                # ì¹´ë“œ ìˆ«ì/ì¸ë¬¼ ì¶”ì¶œ (Ace, Two, Three, ..., Page, Knight, Queen, King)
                card_ranks = ["Ace", "Two", "Three", "Four", "Five", "Six", "Seven", "Eight", "Nine", "Ten", 
                              "Page", "Knight", "Queen", "King"]
                for rank in card_ranks:
                    if rank.lower() in card_name.lower():
                        metadata["rank"] = rank
                        if rank in ["Page", "Knight", "Queen", "King"]:
                            metadata["is_court_card"] = True
                        break
                
                # Tarot-for-beginners ì†ŒìŠ¤ì—ì„œ ì¶”ê°€ ë©”íƒ€ë°ì´í„° íŒŒì‹±
                if metadata["source"] == "Tarot-for-beginners":
                    content = row.get("content", "")
                    if content:
                        # ë³„ìë¦¬ ì¶”ì¶œ
                        astrology = extract_astrology(content)
                        if astrology:
                            metadata["astrology"] = astrology
                            page_content_parts.append(f"ASTROLOGY: {astrology}")
                            
                        # í‚¤ì›Œë“œ ì¶”ì¶œ (KEYWORDS ì„¹ì…˜ì—ì„œ)
                        keywords = extract_tarot_keywords(content)
                        if keywords:
                            metadata["tarot_keywords"] = keywords
                            page_content_parts.append(f"TAROT KEYWORDS: {', '.join(keywords)}")
                            
                        # íŠ¹ì„± ë° ì—­í•  ì¶”ì¶œ
                        traits = extract_traits(content)
                        if traits:
                            metadata["personality_traits"] = traits
                            page_content_parts.append(f"PERSONALITY TRAITS: {', '.join(traits)}")
                            
                        roles = extract_roles(content)
                        if roles:
                            metadata["roles"] = roles
                            page_content_parts.append(f"ROLES: {', '.join(roles)}")
                            
                        # ìƒì§• ì¶”ì¶œ
                        symbols = extract_symbols(content)
                        if symbols:
                            metadata["symbols"] = symbols
                            page_content_parts.append(f"SYMBOLS: {', '.join(symbols)}")
            
            # ì¹´ë“œ ë©”íƒ€ë°ì´í„°ë¥¼ ì„ë² ë”©ì— í¬í•¨
            page_content_parts.append(f"CARD: {card_name}")
            page_content_parts.append(f"TYPE: {card_type}")
            
            # ìŠˆíŠ¸ì™€ ë­í¬ ì •ë³´ ì¶”ê°€
            if metadata.get("suit"):
                page_content_parts.append(f"SUIT: {metadata['suit']}")
            if metadata.get("rank"):
                page_content_parts.append(f"RANK: {metadata['rank']}")
            
            # ë°©í–¥ ì •ë³´ ì¶”ê°€
            if orientation:
                page_content_parts.append(f"ORIENTATION: {orientation}")
                
                # ë°©í–¥ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì¶”ê°€
                if orientation == "upright" or orientation == "both":
                    upright_keywords = extract_keywords_from_content(row.get("content", ""), "upright")
                    if upright_keywords:
                        metadata["upright_keywords"] = upright_keywords
                        page_content_parts.append(f"UPRIGHT KEYWORDS: {upright_keywords}")
                        
                if orientation == "reversed" or orientation == "both":
                    reversed_keywords = extract_keywords_from_content(row.get("reversed", ""), "reversed")
                    if reversed_keywords:
                        metadata["reversed_keywords"] = reversed_keywords
                        page_content_parts.append(f"REVERSED KEYWORDS: {reversed_keywords}")
            
            # Reversed ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if pd.notna(row.get("reversed")) and row.get("reversed").strip():
                reversed_content = row["reversed"].strip()
                metadata["has_reversed"] = True
                
                page_content_parts.append(f"REVERSED MEANING: {reversed_content}")
        
        # ìŠ¤í”„ë ˆë“œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€  
        if pd.notna(row.get("spread_name")) and row.get("spread_name"):
            spread_name = row["spread_name"]
            card_count = row.get("card_count", 0)
            description = row.get("description", "")
            
            # ê°œì„  1: normalized_name ë©”íƒ€ë°ì´í„° ì¶”ê°€
            normalized_name = row.get("normalized_name", "")
            if normalized_name:
                metadata["normalized_name"] = normalized_name
            
            # ê°œì„  2: keywords ë©”íƒ€ë°ì´í„° ì¶”ê°€
            keywords = row.get("keywords", "")
            if keywords:
                metadata["keywords"] = keywords
            
            metadata["spread_name"] = spread_name
            metadata["card_count"] = card_count
            
            # ìŠ¤í”„ë ˆë“œ ë©”íƒ€ë°ì´í„°ë¥¼ ì„ë² ë”©ì— í¬í•¨
            page_content_parts.append(f"SPREAD: {spread_name}")
            
            # ê°œì„  3: normalized_name ì„ë² ë”©ì— í¬í•¨
            if normalized_name:
                page_content_parts.append(f"NORMALIZED NAME: {normalized_name}")
            
            # ê°œì„  4: keywords ì„ë² ë”©ì— í¬í•¨
            if keywords:
                page_content_parts.append(f"KEYWORDS: {keywords}")
            
            if card_count > 0:
                page_content_parts.append(f"CARDS: {card_count} cards")
            if description:
                page_content_parts.append(f"DESCRIPTION: {description}")
                
            # positions ì •ë³´ ì„ë² ë”© (ìŠ¤í”„ë ˆë“œ ë°ì´í„°ì—ë§Œ í•´ë‹¹)
            positions_raw = row.get("positions", "")
            positions_list = parse_positions(positions_raw)
            if positions_list:
                page_content_parts.append("POSITIONS:")
                for pos in positions_list:
                    if isinstance(pos, dict):
                        pos_str = f"{pos.get('position_num', '')}: {pos.get('position_name', '')} - {pos.get('position_meaning', '')}"
                    else:
                        pos_str = str(pos)
                    page_content_parts.append(pos_str)
        
        # ë©”ì¸ ì½˜í…ì¸  ì¶”ê°€
        content = row.get("content", "")
        if content:
            # ì „ì²´ ë‚´ìš©ì„ ì„ë² ë”©ì— í¬í•¨
            page_content_parts.append(f"CONTENT: {content}")
        
        # ìµœì¢… í˜ì´ì§€ ì½˜í…ì¸  ìƒì„±
        final_page_content = "\n\n".join(page_content_parts)
        
        # Document ê°ì²´ ìƒì„±
        doc = Document(
            page_content=final_page_content,
            metadata=metadata
        )
        
        documents.append(doc)
    
    print(f"âœ… {len(documents)}ê°œ Document ê°ì²´ ìƒì„± ì™„ë£Œ (ë©”íƒ€ë°ì´í„° í¬í•¨)")
    return documents

# Tarot-for-beginners ì†ŒìŠ¤ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ë“¤
def extract_also_known_as(content):
    """ALSO KNOWN AS ì •ë³´ ì¶”ì¶œ"""
    import re
    pattern = r"ALSO KNOWN AS\s+(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE)
    if match:
        items = [item.strip() for item in match.group(1).split(",")]
        return items
    return []

def extract_element(content):
    """ELEMENT ì •ë³´ ì¶”ì¶œ"""
    import re
    pattern = r"ELEMENT\s+(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    return ""

def extract_astrology(content):
    """ASTROLOGY ì •ë³´ ì¶”ì¶œ"""
    import re
    pattern = r"ASTROLOGY\s+(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    return ""

def extract_numerology(content):
    """NUMEROLOGY ì •ë³´ ì¶”ì¶œ"""
    import re
    pattern = r"NUMEROLOGY\s+(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    return ""

def extract_tarot_keywords(content):
    """KEYWORDS ì •ë³´ ì¶”ì¶œ"""
    import re
    pattern = r"KEYWORDS\s+(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE)
    if match:
        keywords = [kw.strip() for kw in match.group(1).split(",")]
        return keywords
    return []

def extract_mythological_association(content):
    """ì‹ í™”ì  ì—°ê´€ì„± ì¶”ì¶œ"""
    import re
    # Mystic Meanings ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
    pattern = r"Mystic Meanings.*?Chiron(.*?)(?:\n|$)"
    match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
    if match:
        return "Centaur Chiron, the wounded healer"
    return ""

def extract_symbols(content):
    """ìƒì§• ì¶”ì¶œ"""
    import re
    # ë‚´ìš©ì—ì„œ í‚¤ ë‹¨ì–´ë¡œ ìƒì§• ì¶”ì¶œ
    symbols = []
    key_symbols = ["Keys", "Chalice", "Cup", "Throne", "Cross", "Wand", "Pentacle", "Sword"]
    
    for symbol in key_symbols:
        if re.search(rf"\b{symbol}\b", content, re.IGNORECASE):
            symbols.append(symbol)
    
    return symbols

def extract_related_cards(content):
    """ê´€ë ¨ ì¹´ë“œ ì¶”ì¶œ"""
    import re
    result = {}
    
    # Supporting and Opposing Cards ì„¹ì…˜ ì°¾ê¸°
    pattern = r"Supporting and Opposing Cards(.*?)(?:(?:^#)|$)"
    match = re.search(pattern, content, re.IGNORECASE | re.MULTILINE | re.DOTALL)
    
    if match:
        section = match.group(1)
        
        # Supporting ì¹´ë“œ ì°¾ê¸°
        supporting_pattern = r"combined with\s+(.*?),\s+The\s+(\w+)\s+indicates"
        supporting_matches = re.findall(supporting_pattern, section, re.IGNORECASE)
        
        supporting_cards = []
        for match in supporting_matches:
            if len(match) >= 2:
                supporting_cards.append(f"The {match[1]}")
                supporting_cards.append(match[0])
        
        # Opposing ì¹´ë“œ ì°¾ê¸°
        opposing_pattern = r"free spirits,\s+(.*?),\s+often indicate"
        opposing_match = re.search(opposing_pattern, section, re.IGNORECASE)
        
        opposing_cards = []
        if opposing_match:
            cards_text = opposing_match.group(1)
            cards = re.findall(r"The\s+(\w+)", cards_text)
            opposing_cards = [f"The {card}" for card in cards]
        
        if supporting_cards:
            result["supporting_cards"] = supporting_cards
        if opposing_cards:
            result["opposing_cards"] = opposing_cards
    
    return result

def extract_traits(content):
    """ì¹´ë“œì˜ íŠ¹ì„± ì¶”ì¶œ"""
    import re
    traits = []
    
    # íŠ¹ì„± ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
    trait_keywords = ["compassionate", "understanding", "nurturing", "healing", "empathetic", "intuitive"]
    
    for trait in trait_keywords:
        if re.search(rf"\b{trait}\b", content, re.IGNORECASE):
            traits.append(trait.capitalize())
    
    return traits

def extract_roles(content):
    """ì¹´ë“œì˜ ì—­í•  ì¶”ì¶œ"""
    import re
    roles = []
    
    # ì—­í•  ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
    role_keywords = ["healer", "mother", "nurturer", "teacher", "guide", "mentor"]
    
    for role in role_keywords:
        if re.search(rf"\b{role}\b", content, re.IGNORECASE):
            roles.append(role.capitalize())
    
    return roles

def extract_keywords_from_content(text, orientation_type):
    """ì¹´ë“œ ì˜ë¯¸ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    if not text or not isinstance(text, str):
        return ""
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§ (ê°„ë‹¨í•œ ë²„ì „)
    # ì‹¤ì œë¡œëŠ” NLP ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë” ì •êµí•˜ê²Œ ì¶”ì¶œ ê°€ëŠ¥
    max_words = 10
    words = text.lower().split()
    filtered_words = [word for word in words if len(word) > 3 and word.isalpha()]
    
    # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ ê¸¸ì´ ì œí•œ
    unique_words = list(set(filtered_words))[:max_words]
    
    return ", ".join(unique_words)

def summarize_text(text, max_length=100):
    """í…ìŠ¤íŠ¸ ìš”ì•½ (ê°„ë‹¨í•œ ë²„ì „)"""
    if not text or not isinstance(text, str):
        return ""
    
    # ì²« ë¬¸ì¥ ë˜ëŠ” ë‹¨ë½ ì¶”ì¶œ
    if len(text) <= max_length:
        return text
    
    # ì²« ë¬¸ì¥ ì¶”ì¶œ ì‹œë„
    import re
    sentences = re.split(r'[.!?]\s+', text)
    if sentences and len(sentences[0]) < max_length:
        return sentences[0]
    
    # ì²« ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ë©´ ë‹¨ìˆœ ì ˆë‹¨
    return text[:max_length] + "..."

def main():
    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
    print("ğŸ¤– ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model_name = "BAAI/bge-m3"
    model_kwargs = {"device": "cuda"}  # GPU ì‚¬ìš© ì‹œ "cuda"ë¡œ ë³€ê²½
    encode_kwargs = {"normalize_embeddings": True}
    
    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs=model_kwargs,
        encode_kwargs=encode_kwargs
    )
    print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
    
    # 1. ì¹´ë“œ ë°ì´í„° ì²˜ë¦¬
    print("\n" + "="*50)
    print("ğŸ“š ì¹´ë“œ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    card_documents = load_csv_to_documents(CARD_CSV_PATH)
    
    if card_documents:
        print(f"âœ… {len(card_documents)}ê°œ ì¹´ë“œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        
        # ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ìƒì„±
        print("\nğŸ” ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        try:
            card_db = FAISS.from_documents(card_documents, embeddings)
            print("âœ… ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            
            # ì¹´ë“œ ì¸ë±ìŠ¤ ì €ì¥
            card_save_path = "tarot_card_faiss_index"
            card_db.save_local(card_save_path)
            print(f"âœ… ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ì €ì¥: {card_save_path}")
            
            # ì¹´ë“œ ë°ì´í„° í†µê³„
            print_card_statistics(card_documents)
            
        except Exception as e:
            print(f"âŒ ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
    
    # 2. ìŠ¤í”„ë ˆë“œ ë°ì´í„° ì²˜ë¦¬
    print("\n" + "="*50)
    print("ğŸ“š ìŠ¤í”„ë ˆë“œ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    spread_documents = load_csv_to_documents(SPREAD_CSV_PATH)
    
    if spread_documents:
        print(f"âœ… {len(spread_documents)}ê°œ ìŠ¤í”„ë ˆë“œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        
        # ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ìƒì„±
        print("\nğŸ” ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        try:
            spread_db = FAISS.from_documents(spread_documents, embeddings)
            print("âœ… ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            
            # ìŠ¤í”„ë ˆë“œ ì¸ë±ìŠ¤ ì €ì¥
            spread_save_path = "tarot_spread_faiss_index"
            spread_db.save_local(spread_save_path)
            print(f"âœ… ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ì €ì¥: {spread_save_path}")
            
            # ìŠ¤í”„ë ˆë“œ ë°ì´í„° í†µê³„
            print_spread_statistics(spread_documents)
            
        except Exception as e:
            print(f"âŒ ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
    
    # 3. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    if card_documents and spread_documents:
        print("\n" + "="*50)
        print("ğŸ§ª ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ì¹´ë“œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        print("\nğŸƒ ì¹´ë“œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:")
        card_queries = ["What does The Fool card mean?", "Ace of Cups meaning", "Death card reversed"]
        test_queries(card_db, card_queries, "ì¹´ë“œ")
        
        # ìŠ¤í”„ë ˆë“œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        print("\nğŸ”® ìŠ¤í”„ë ˆë“œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:")
        spread_queries = ["How to do Celtic Cross spread?", "3 card spread", "love relationship spread"]
        test_queries(spread_db, spread_queries, "ìŠ¤í”„ë ˆë“œ")
    
    print(f"\nğŸ‰ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")

def print_card_statistics(documents):
    """ì¹´ë“œ ë°ì´í„° í†µê³„ ì¶œë ¥"""
    print(f"\nğŸ“Š ì¹´ë“œ ë°ì´í„° í†µê³„:")
    print(f"ì´ ì¹´ë“œ ìˆ˜: {len(documents)}")
    
    # ì¹´ë“œ íƒ€ì…ë³„
    card_types = {}
    orientations = {}
    suits = {}
    ranks = {}
    
    for doc in documents:
        meta = doc.metadata
        
        # ì¹´ë“œ íƒ€ì… í†µê³„
        card_type = meta.get("card_type", "unknown")
        card_types[card_type] = card_types.get(card_type, 0) + 1
        
        # ë°©í–¥ í†µê³„
        orientation = meta.get("orientation", "unknown")
        orientations[orientation] = orientations.get(orientation, 0) + 1
        
        # ìŠˆíŠ¸ í†µê³„ (Minor Arcana ì¹´ë“œë§Œ)
        if meta.get("suit"):
            suit = meta.get("suit")
            suits[suit] = suits.get(suit, 0) + 1
            
        # ë­í¬ í†µê³„ (Minor Arcana ì¹´ë“œë§Œ)
        if meta.get("rank"):
            rank = meta.get("rank")
            ranks[rank] = ranks.get(rank, 0) + 1
    
    print("ğŸƒ ì¹´ë“œ íƒ€ì…ë³„:")
    for card_type, count in card_types.items():
        print(f"  {card_type}: {count}ê°œ")
    
    print("ğŸ”„ ë°©í–¥ë³„:")
    for orientation, count in orientations.items():
        print(f"  {orientation}: {count}ê°œ")
    
    if suits:
        print("â™ ï¸ ìŠˆíŠ¸ë³„:")
        for suit, count in suits.items():
            print(f"  {suit}: {count}ê°œ")
    
    if ranks:
        print("ğŸ‘‘ ë­í¬ë³„:")
        for rank, count in sorted(ranks.items(), key=lambda x: (
            0 if x[0] == "Ace" else
            1 if x[0] == "Two" else
            2 if x[0] == "Three" else
            3 if x[0] == "Four" else
            4 if x[0] == "Five" else
            5 if x[0] == "Six" else
            6 if x[0] == "Seven" else
            7 if x[0] == "Eight" else
            8 if x[0] == "Nine" else
            9 if x[0] == "Ten" else
            10 if x[0] == "Page" else
            11 if x[0] == "Knight" else
            12 if x[0] == "Queen" else
            13 if x[0] == "King" else 14
        )):
            print(f"  {rank}: {count}ê°œ")

def print_spread_statistics(documents):
    """ìŠ¤í”„ë ˆë“œ ë°ì´í„° í†µê³„ ì¶œë ¥"""
    print(f"\nğŸ“Š ìŠ¤í”„ë ˆë“œ ë°ì´í„° í†µê³„:")
    print(f"ì´ ìŠ¤í”„ë ˆë“œ ìˆ˜: {len(documents)}")
    
    # ì¹´ë“œ ìˆ˜ë³„ ë¶„í¬
    card_counts = {}
    # ê°œì„ : í¬ì§€ì…˜ ìˆ˜ ë¶„í¬ ì¶”ê°€
    position_counts = {}
    
    for doc in documents:
        card_count = doc.metadata.get("card_count", 0)
        card_counts[card_count] = card_counts.get(card_count, 0) + 1
        
        # í¬ì§€ì…˜ ìˆ˜ í†µê³„ ì¶”ê°€
        positions_count = doc.metadata.get("positions_count", 0)
        position_counts[positions_count] = position_counts.get(positions_count, 0) + 1
    
    print("ğŸ¯ ì¹´ë“œ ìˆ˜ë³„ ë¶„í¬:")
    for card_count in sorted(card_counts.keys()):
        count = card_counts[card_count]
        print(f"  {card_count}ì¥: {count}ê°œ")
    
    # í¬ì§€ì…˜ ìˆ˜ í†µê³„ ì¶œë ¥
    print("ğŸ“ í¬ì§€ì…˜ ìˆ˜ë³„ ë¶„í¬:")
    for positions_count in sorted(position_counts.keys()):
        count = position_counts[positions_count]
        print(f"  í¬ì§€ì…˜ {positions_count}ê°œ: {count}ê°œ ìŠ¤í”„ë ˆë“œ")

def test_queries(db, queries, db_type):
    """ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    for query in queries:
        print(f"\nğŸ” ì¿¼ë¦¬: {query}")
        try:
            results = db.similarity_search(query, k=2)
            print(f"ìƒìœ„ 2ê°œ {db_type} ê²°ê³¼:")
            
            for i, doc in enumerate(results, 1):
                metadata = doc.metadata
                print(f"\n  ê²°ê³¼ {i}:")
                print(f"    ID: {metadata.get('id', 'Unknown')}")
                
                # ì¹´ë“œ ë˜ëŠ” ìŠ¤í”„ë ˆë“œ ì •ë³´
                if metadata.get('card_name'):
                    print(f"    ì¹´ë“œ: {metadata['card_name']} ({metadata.get('card_type', '')})")
                    # ê°œì„ : ì¹´ë“œ ë©”íƒ€ë°ì´í„° ì¶”ê°€ í‘œì‹œ
                    if metadata.get('suit'):
                        print(f"    ìŠˆíŠ¸: {metadata['suit']}")
                    if metadata.get('rank'):
                        print(f"    ë­í¬: {metadata['rank']}")
                    if metadata.get('upright_keywords'):
                        print(f"    ì •ë°©í–¥ í‚¤ì›Œë“œ: {metadata['upright_keywords'][:100]}...")
                    if metadata.get('reversed_keywords'):
                        print(f"    ì—­ë°©í–¥ í‚¤ì›Œë“œ: {metadata['reversed_keywords'][:100]}...")
                
                if metadata.get('spread_name'):
                    print(f"    ìŠ¤í”„ë ˆë“œ: {metadata['spread_name']} ({metadata.get('card_count', 0)}ì¥)")
                    # ê°œì„ : ì •ê·œí™”ëœ ì´ë¦„ê³¼ í‚¤ì›Œë“œ ì •ë³´ í‘œì‹œ
                    if metadata.get('normalized_name'):
                        print(f"    ì •ê·œí™” ì´ë¦„: {metadata['normalized_name']}")
                    if metadata.get('keywords'):
                        print(f"    í‚¤ì›Œë“œ: {metadata['keywords'][:100]}...")
                    if metadata.get('positions_count'):
                        print(f"    í¬ì§€ì…˜ ìˆ˜: {metadata['positions_count']}")
                
                print(f"    ì†ŒìŠ¤: {metadata.get('source', 'Unknown')}")
                print(f"    ë‚´ìš©: {doc.page_content[:100]}...")
                
        except Exception as e:
            print(f"    âŒ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()