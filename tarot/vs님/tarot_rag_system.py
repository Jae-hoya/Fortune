# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# !pip install flashrank faiss-cpu sentence-transformers langchain langchain-community rank-bm25

import os
import numpy as np
from typing import List, Tuple, Dict, Any
from flashrank import Ranker, RerankRequest
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.docstore.document import Document
from rank_bm25 import BM25Okapi

def convert_numpy_types(obj):
    if isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(v) for v in obj]
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    else:
        return obj

class BM25Retriever:
    """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°"""
    
    def __init__(self, documents: List[Document]):
        self.documents = documents
        self.doc_contents = [doc.page_content for doc in documents]
        
        # ë¬¸ì„œ í† í°í™” (ê°„ë‹¨í•œ ê³µë°± ê¸°ë°˜ í† í°í™”)
        self.tokenized_docs = [doc.split() for doc in self.doc_contents]
        
        # BM25 ì¸ë±ìŠ¤ ìƒì„±
        self.bm25 = BM25Okapi(self.tokenized_docs)
        print(f"ğŸ”¤ BM25 index created with {len(documents)} documents")
        
    def retrieve(self, query: str, top_k: int = 5) -> List[Tuple[Document, float]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê´€ë ¨ ë¬¸ì„œì™€ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # ì¿¼ë¦¬ í† í°í™”
        tokenized_query = query.split()
        
        # BM25 ì ìˆ˜ ê³„ì‚°
        scores = self.bm25.get_scores(tokenized_query)
        
        # ìƒìœ„ kê°œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        # ê²°ê³¼ ë¬¸ì„œì™€ ì ìˆ˜ ê²°í•©
        results = [(self.documents[idx], scores[idx]) for idx in top_indices]
        
        return results

class FlashRankReranker:
    """FlashRankë¥¼ ì‚¬ìš©í•œ Reranker í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "ms-marco-MiniLM-L-12-v2"):
        try:
            self.ranker = Ranker(model_name=model_name, cache_dir="/tmp")
            print(f"âš¡ FlashRank Reranker initialized with model: {model_name}")
        except Exception as e:
            print(f"Error initializing FlashRank: {e}")
            # í´ë°± ëª¨ë¸ ì‹œë„
            self.ranker = Ranker(model_name="ms-marco-MiniLM-L-6-v2", cache_dir="/tmp")
            print("FlashRank initialized with fallback model")
    
    def rerank(self, query: str, documents: List[Document], top_k: int = None) -> List[Tuple[Document, float]]:
        """ë¬¸ì„œë“¤ì„ ì¬ìˆœìœ„í™”í•˜ê³  ì ìˆ˜ì™€ í•¨ê»˜ ë°˜í™˜"""
        if not documents:
            return []
        
        if top_k is None or top_k > len(documents):
            top_k = len(documents)
        
        print(f"âš¡ Reranking {len(documents)} documents...")
        
        try:
            # FlashRankìš© ë°ì´í„° ì¤€ë¹„
            passages = []
            for i, doc in enumerate(documents):
                passages.append({
                    "id": i,
                    "text": doc.page_content,
                    "meta": doc.metadata
                })
            
            # RerankRequest ê°ì²´ ìƒì„±
            rerank_request = RerankRequest(query=query, passages=passages)
            
            # ì¬ìˆœìœ„í™” ì‹¤í–‰
            results = self.ranker.rerank(rerank_request)
            
            # ê²°ê³¼ ì •ë ¬ (ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
            reranked_docs = []
            for result in results[:top_k]:
                original_doc = documents[result['id']]
                score = result['score']
                reranked_docs.append((original_doc, score))
            
            print(f"âœ… Reranking completed. Top score: {reranked_docs[0][1]:.4f}")
            return reranked_docs
            
        except Exception as e:
            print(f"âŒ Error during reranking: {e}")
            # í´ë°±: ì›ë³¸ ìˆœì„œ ìœ ì§€í•˜ë©° ë”ë¯¸ ì ìˆ˜ í• ë‹¹
            return [(doc, 0.0) for doc in documents[:top_k]]

class HybridRetriever:
    """FAISS(Semantic) + BM25(Keyword) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""
    
    def __init__(
        self, 
        semantic_retriever: FAISS, 
        keyword_retriever: BM25Retriever,
        semantic_weight: float = 0.8,
        keyword_weight: float = 0.2
    ):
        self.semantic_retriever = semantic_retriever
        self.keyword_retriever = keyword_retriever
        
        # ê°€ì¤‘ì¹˜ ê²€ì¦ ë° ì„¤ì •
        assert abs(semantic_weight + keyword_weight - 1.0) < 1e-6, "ê°€ì¤‘ì¹˜ í•©ì€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤"
        
        self.semantic_weight = semantic_weight
        self.keyword_weight = keyword_weight
        
        print(f"ğŸ”€ HybridRetriever initialized: Semantic={semantic_weight}, Keyword={keyword_weight}")
    
    def retrieve(self, query: str, top_k: int = 10) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print(f"ğŸ” Hybrid search for: '{query}' (top_k={top_k})")
        
        # 1. ì‹œë©˜í‹± ê²€ìƒ‰ ìˆ˜í–‰
        semantic_results = self.semantic_retriever.similarity_search_with_score(query, k=top_k*2)
        print(f"ğŸ“Š Semantic search: {len(semantic_results)} results")
        
        # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜í–‰
        keyword_results = self.keyword_retriever.retrieve(query, top_k=top_k*2)
        print(f"ğŸ”¤ Keyword search: {len(keyword_results)} results")
        
        # 3. ê²°ê³¼ ë³‘í•© ë° ê°€ì¤‘ì¹˜ ì ìš©
        combined_scores = {}
        
        # ì‹œë©˜í‹± ê²°ê³¼ ì²˜ë¦¬
        for doc, score in semantic_results:
            doc_id = self._get_doc_id(doc)
            # FAISSëŠ” ê±°ë¦¬ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (1 / (1 + distance))
            similarity = 1.0 / (1.0 + score)
            combined_scores[doc_id] = {
                "doc": doc,
                "semantic_score": similarity,
                "keyword_score": 0.0,
                "final_score": self.semantic_weight * similarity
            }
        
        # í‚¤ì›Œë“œ ê²°ê³¼ ì²˜ë¦¬
        for doc, score in keyword_results:
            doc_id = self._get_doc_id(doc)
            # BM25 ì ìˆ˜ ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
            normalized_score = score / (score + 1.0) if score > 0 else 0.0
            
            if doc_id in combined_scores:
                combined_scores[doc_id]["keyword_score"] = normalized_score
                combined_scores[doc_id]["final_score"] += self.keyword_weight * normalized_score
            else:
                combined_scores[doc_id] = {
                    "doc": doc,
                    "semantic_score": 0.0,
                    "keyword_score": normalized_score,
                    "final_score": self.keyword_weight * normalized_score
                }
        
        # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
        sorted_results = sorted(
            combined_scores.values(), 
            key=lambda x: x["final_score"], 
            reverse=True
        )
        
        print(f"âœ… Hybrid search completed: {len(sorted_results)} combined results")
        
        # ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜
        return [item["doc"] for item in sorted_results[:top_k]]
    
    def _get_doc_id(self, doc: Document) -> str:
        """ë¬¸ì„œì˜ ê³ ìœ  IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # íƒ€ë¡œ CSV ë©”íƒ€ë°ì´í„°ì— IDê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if doc.metadata and "id" in doc.metadata:
            return str(doc.metadata["id"])
        
        # í´ë°±: ë‚´ìš© í•´ì‹œë¡œ ID ìƒì„±
        content_hash = hash(doc.page_content[:100])
        return f"doc_{content_hash}"

class TarotRAGSystem:
    """íƒ€ë¡œ Hybrid RAG ì‹œìŠ¤í…œ: ë¶„ë¦¬ëœ ì¹´ë“œ/ìŠ¤í”„ë ˆë“œ FAISS + BM25 + FlashRank"""
    
    def __init__(self, 
                 card_faiss_path: str = "tarot_card_faiss_index",
                 spread_faiss_path: str = "tarot_spread_faiss_index",
                 embedding_model_name: str = "BAAI/bge-m3",
                 reranker_model_name: str = "ms-marco-MiniLM-L-12-v2",
                 semantic_weight: float = 0.8,
                 keyword_weight: float = 0.2):
        """
        íƒ€ë¡œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            card_faiss_path: ì¹´ë“œ FAISS ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ
            spread_faiss_path: ìŠ¤í”„ë ˆë“œ FAISS ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ
            embedding_model_name: ì„ë² ë”© ëª¨ë¸ëª…
            reranker_model_name: ë¦¬ë­ì»¤ ëª¨ë¸ëª…
            semantic_weight: ì‹œë©˜í‹± ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            keyword_weight: í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        """
        print("=" * 80)
        print("ğŸ”® TAROT HYBRID RAG SYSTEM INITIALIZATION")
        print("=" * 80)
        
        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("ğŸ“š Loading embedding model...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model_name,
            model_kwargs={'device': 'cpu'},  # GPU ì‚¬ìš© ì‹œ 'cuda'ë¡œ ë³€ê²½
            encode_kwargs={'normalize_embeddings': True}
        )
        print(f"âœ… Embedding model loaded: {embedding_model_name}")
        
        # 2. ì¹´ë“œ FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        print("ğŸƒ Loading Card FAISS index...")
        try:
            self.card_vectorstore = FAISS.load_local(
                card_faiss_path, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"âœ… Card FAISS loaded: {self.card_vectorstore.index.ntotal} documents")
        except Exception as e:
            print(f"âŒ Error loading Card FAISS index: {e}")
            self.card_vectorstore = None
        
        # 3. ìŠ¤í”„ë ˆë“œ FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        print("ğŸ”® Loading Spread FAISS index...")
        try:
            self.spread_vectorstore = FAISS.load_local(
                spread_faiss_path, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"âœ… Spread FAISS loaded: {self.spread_vectorstore.index.ntotal} documents")
        except Exception as e:
            print(f"âŒ Error loading Spread FAISS index: {e}")
            self.spread_vectorstore = None
        
        # 4. ì¹´ë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        if self.card_vectorstore:
            print("ğŸƒ Initializing Card hybrid retriever...")
            card_docs = self._extract_documents(self.card_vectorstore)
            self.card_bm25 = BM25Retriever(card_docs)
            self.card_hybrid = HybridRetriever(
                semantic_retriever=self.card_vectorstore,
                keyword_retriever=self.card_bm25,
                semantic_weight=semantic_weight,
                keyword_weight=keyword_weight
            )
        
        # 5. ìŠ¤í”„ë ˆë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        if self.spread_vectorstore:
            print("ğŸ”® Initializing Spread hybrid retriever...")
            spread_docs = self._extract_documents(self.spread_vectorstore)
            self.spread_bm25 = BM25Retriever(spread_docs)
            self.spread_hybrid = HybridRetriever(
                semantic_retriever=self.spread_vectorstore,
                keyword_retriever=self.spread_bm25,
                semantic_weight=semantic_weight,
                keyword_weight=keyword_weight
            )
        
        # 6. FlashRank Reranker ì´ˆê¸°í™”
        print("âš¡ Initializing FlashRank reranker...")
        self.reranker = FlashRankReranker(model_name=reranker_model_name)
        
        print("ğŸ‰ TAROT HYBRID RAG SYSTEM READY!")
        print("=" * 80)
    
    def _extract_documents(self, vectorstore: FAISS) -> List[Document]:
        """FAISSì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¶”ì¶œ"""
        try:
            all_docs = []
            docstore = vectorstore.docstore._dict
            for doc_id, doc in docstore.items():
                all_docs.append(doc)
            return all_docs
        except Exception as e:
            print(f"âŒ Error extracting documents: {e}")
            return []
    
    def search_cards(self, 
                    query: str, 
                    hybrid_k: int = 20, 
                    final_k: int = 5,
                    show_details: bool = True) -> List[Tuple[Document, float]]:
        """
        ì¹´ë“œ ì˜ë¯¸ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            hybrid_k: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
            final_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            show_details: ê²€ìƒ‰ ê³¼ì • ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        if not self.card_vectorstore:
            print("âŒ Card FAISS index not loaded")
            return []
        
        if show_details:
            print(f"\nğŸƒ CARD SEARCH: {query}")
            print("-" * 50)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        hybrid_docs = self.card_hybrid.retrieve(query, top_k=hybrid_k)
        
        if not hybrid_docs:
            return []
        
        # FlashRank ì¬ìˆœìœ„í™”
        if show_details:
            print("âš¡ Reranking card results...")
            
        reranked_results = self.reranker.rerank(query, hybrid_docs, top_k=final_k)
            
        return reranked_results
    
    def search_spreads(self, 
                      query: str, 
                      hybrid_k: int = 20, 
                      final_k: int = 5,
                      show_details: bool = True) -> List[Tuple[Document, float]]:
        """
        ìŠ¤í”„ë ˆë“œ ì„¤ëª… ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            hybrid_k: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
            final_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            show_details: ê²€ìƒ‰ ê³¼ì • ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        if not self.spread_vectorstore:
            print("âŒ Spread FAISS index not loaded")
            return []
        
        if show_details:
            print(f"\nğŸ”® SPREAD SEARCH: {query}")
            print("-" * 50)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        hybrid_docs = self.spread_hybrid.retrieve(query, top_k=hybrid_k)
        
        if not hybrid_docs:
            return []
        
        # FlashRank ì¬ìˆœìœ„í™”
        if show_details:
            print("âš¡ Reranking spread results...")
            
        reranked_results = self.reranker.rerank(query, hybrid_docs, top_k=final_k)
            
        return reranked_results
    
    def search_auto(self, 
                   query: str, 
                   final_k: int = 5,
                   show_details: bool = True) -> Dict[str, List[Tuple[Document, float]]]:
        """
        ìë™ ê²€ìƒ‰ - ì¿¼ë¦¬ì— ë”°ë¼ ì¹´ë“œ/ìŠ¤í”„ë ˆë“œ ìë™ íŒë‹¨
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            final_k: ê° íƒ€ì…ë³„ ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            show_details: ê²€ìƒ‰ ê³¼ì • ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            {"cards": [...], "spreads": [...]} í˜•íƒœì˜ ê²°ê³¼
        """
        if show_details:
            print(f"\nğŸ”® AUTO SEARCH: {query}")
            print("=" * 60)
        
        results = {"cards": [], "spreads": []}
        
        # ì¿¼ë¦¬ í‚¤ì›Œë“œ ë¶„ì„
        query_lower = query.lower()
        
        # ì¹´ë“œ ê´€ë ¨ í‚¤ì›Œë“œ
        card_keywords = ["card", "meaning", "interpretation", "arcana", "reversed", "upright"]
        
        # ìŠ¤í”„ë ˆë“œ ê´€ë ¨ í‚¤ì›Œë“œ (ì‹¤ì œ ìŠ¤í”„ë ˆë“œëª… ê¸°ë°˜ìœ¼ë¡œ í™•ì¥)
        spread_keywords = ["spread", "layout", "reading", "position", "cross", "celtic", "three card", 
                          "past present future", "chakra", "horseshoe", "tree of life", "decision", 
                          "love", "relationship", "career", "money", "health", "daily", "yes no", 
                          "magical lottery", "astrological", "one card", "pull", "oracle", "guidance",
                          "triangle", "heart", "soul mate", "karmic", "wish", "bottom line", "choice",
                          "options", "advice", "spiritual", "weekly", "monthly", "yearly", "star",
                          "marketplace", "business", "lawsuit", "family", "pregnancy", "divorce",
                          "vacation", "trip", "relocation", "destiny", "fears", "reincarnation"]
        
        # ë©”ì´ì € ì•„ë¥´ì¹´ë‚˜ ì¹´ë“œëª…
        major_arcana = ["fool", "magician", "priestess", "empress", "emperor", "hierophant", "lovers", 
                       "chariot", "strength", "hermit", "wheel", "justice", "hanged", "death", 
                       "temperance", "devil", "tower", "star", "moon", "sun", "judgement", "world"]
        
        # ë§ˆì´ë„ˆ ì•„ë¥´ì¹´ë‚˜ ì¹´ë“œëª… (56ì¥ ì „ì²´)
        minor_arcana = [
            # Cups (14ì¥)
            "ace of cups", "two of cups", "three of cups", "four of cups", "five of cups",
            "six of cups", "seven of cups", "eight of cups", "nine of cups", "ten of cups",
            "page of cups", "knight of cups", "queen of cups", "king of cups",
            
            # Pentacles (14ì¥)
            "ace of pentacles", "two of pentacles", "three of pentacles", "four of pentacles", "five of pentacles",
            "six of pentacles", "seven of pentacles", "eight of pentacles", "nine of pentacles", "ten of pentacles",
            "page of pentacles", "knight of pentacles", "queen of pentacles", "king of pentacles",
            
            # Swords (14ì¥)
            "ace of swords", "two of swords", "three of swords", "four of swords", "five of swords",
            "six of swords", "seven of swords", "eight of swords", "nine of swords", "ten of swords",
            "page of swords", "knight of swords", "queen of swords", "king of swords",
            
            # Wands (14ì¥)
            "ace of wands", "two of wands", "three of wands", "four of wands", "five of wands",
            "six of wands", "seven of wands", "eight of wands", "nine of wands", "ten of wands",
            "page of wands", "knight of wands", "queen of wands", "king of wands",
            
            # ìˆ˜íŠ¸ëª…ë“¤
            "cups", "pentacles", "swords", "wands", "ace", "king", "queen", "knight", "page"
        ]
        
        # ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ ê²°ì •
        has_card_keywords = any(keyword in query_lower for keyword in card_keywords)
        has_spread_keywords = any(keyword in query_lower for keyword in spread_keywords)
        has_specific_card = any(card in query_lower for card in major_arcana + minor_arcana)
        
        # ì¹´ë“œ ê²€ìƒ‰
        if has_card_keywords or has_specific_card or not has_spread_keywords:
            if show_details:
                print("ğŸƒ Searching cards...")
            results["cards"] = self.search_cards(query, final_k=final_k, show_details=False)
        
        # ìŠ¤í”„ë ˆë“œ ê²€ìƒ‰
        if has_spread_keywords or not (has_card_keywords or has_specific_card):
            if show_details:
                print("ğŸ”® Searching spreads...")
            results["spreads"] = self.search_spreads(query, final_k=final_k, show_details=False)
        
        return results
    
    def pretty_print_results(self, results: List[Tuple[Document, float]], result_type: str = ""):
        """íƒ€ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥"""
        if not results:
            print(f"âŒ No {result_type} results found")
            return
        
        type_emoji = "ğŸƒ" if "card" in result_type.lower() else "ğŸ”®" if "spread" in result_type.lower() else "ğŸ”"
        print(f"\n{type_emoji} {result_type.upper()} RESULTS ({len(results)} documents)")
        print("=" * 60)
        
        for i, (doc, score) in enumerate(results, 1):
            metadata = doc.metadata
            
            print(f"\n{type_emoji} Result {i} (Score: {score:.4f})")
            print("-" * 30)
            
            # ì¹´ë“œ ì •ë³´ ì¶œë ¥
            if metadata.get("card_name"):
                card_name = metadata['card_name']
                card_type = metadata.get('card_type', '')
                orientation = metadata.get('orientation', '')
                print(f"ğŸƒ Card: {card_name} ({card_type})")
                if orientation and orientation != "both":
                    print(f"ğŸ”„ Orientation: {orientation}")
            
            # ìŠ¤í”„ë ˆë“œ ì •ë³´ ì¶œë ¥
            if metadata.get("spread_name"):
                spread_name = metadata['spread_name']
                card_count = metadata.get('card_count', 0)
                print(f"ğŸ”® Spread: {spread_name}")
                if card_count > 0:
                    print(f"ğŸ¯ Cards: {card_count}")
            
            # ë©”íƒ€ë°ì´í„° ì¶œë ¥
            print(f"ğŸ“š Source: {metadata.get('source', 'Unknown')}")
            
            # ë‚´ìš© ì¶œë ¥ (ì²˜ìŒ 200ì)
            content = doc.page_content
            if len(content) > 200:
                content = content[:200] + "..."
            print(f"ğŸ“ Content: {content}")

    def doc_to_card_info(self, doc: Document, orientation: str = "upright") -> dict:
        """ì¹´ë“œ Documentì—ì„œ ë©”íƒ€ë°ì´í„°ì™€ ì˜ë¯¸ë¥¼ ì¶”ì¶œí•´ dictë¡œ ë°˜í™˜ (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        meta = doc.metadata
        info = dict(meta)  # ëª¨ë“  ë©”íƒ€ë°ì´í„° ë³µì‚¬
        info["orientation"] = orientation
        # orientationë³„ ì˜ë¯¸ ì¶”ì¶œ
        if orientation == "upright":
            if meta.get("upright_keywords"):
                info["meaning"] = meta.get("upright_keywords")
            elif meta.get("tarot_keywords"):
                info["meaning"] = ", ".join(meta.get("tarot_keywords"))
            else:
                info["meaning"] = doc.page_content[:200]
        elif orientation == "reversed":
            if meta.get("reversed_keywords"):
                info["meaning"] = meta.get("reversed_keywords")
            elif meta.get("tarot_keywords"):
                info["meaning"] = ", ".join(meta.get("tarot_keywords"))
            else:
                info["meaning"] = doc.page_content[:200]
        else:
            info["meaning"] = doc.page_content[:200]
        info["content"] = doc.page_content
        return convert_numpy_types(info)

    def search_card_meaning(self, card_name: str, orientation: str = "upright", show_details: bool = False) -> dict:
        """ì¹´ë“œ ì´ë¦„ê³¼ ë°©í–¥ìœ¼ë¡œ ì˜ë¯¸/í‚¤ì›Œë“œ ë“± ë©”íƒ€ë°ì´í„° dict ë°˜í™˜"""
        if not self.card_vectorstore:
            return {"success": False, "message": "Card FAISS index not loaded"}
        query = f"{card_name} {orientation} meaning"
        results = self.search_cards(query, final_k=1, show_details=show_details)
        if not results:
            return {"success": False, "message": "No result"}
        doc, score = results[0]
        info = self.doc_to_card_info(doc, orientation)
        info["success"] = True
        info["score"] = score
        return info

    def doc_to_spread_info(self, doc: Document) -> dict:
        """ìŠ¤í”„ë ˆë“œ Documentì—ì„œ ë©”íƒ€ë°ì´í„°ì™€ positions ë“± ì¶”ì¶œí•´ dictë¡œ ë°˜í™˜ (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        meta = doc.metadata
        info = dict(meta)  # ëª¨ë“  ë©”íƒ€ë°ì´í„° ë³µì‚¬
        info["content"] = doc.page_content
        return convert_numpy_types(info)

    def search_spread_info(self, spread_name: str, show_details: bool = False) -> dict:
        """ìŠ¤í”„ë ˆë“œ ì´ë¦„ìœ¼ë¡œ positions ë“± ë©”íƒ€ë°ì´í„° dict ë°˜í™˜"""
        if not self.spread_vectorstore:
            return {"success": False, "message": "Spread FAISS index not loaded"}
        query = f"{spread_name} positions"
        results = self.search_spreads(query, final_k=1, show_details=show_details)
        if not results:
            return {"success": False, "message": "No result"}
        doc, score = results[0]
        info = self.doc_to_spread_info(doc)
        info["success"] = True
        info["score"] = score
        return info

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - íƒ€ë¡œ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_system = TarotRAGSystem(
        card_faiss_path="tarot_card_faiss_index",
        spread_faiss_path="tarot_spread_faiss_index",
        embedding_model_name="BAAI/bge-m3",
        reranker_model_name="ms-marco-MiniLM-L-12-v2",
        semantic_weight=0.8,
        keyword_weight=0.2
    )
    
    # íƒ€ë¡œ ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "What does The Fool card mean?",  # ì¹´ë“œ ì¿¼ë¦¬
        "How to do a Celtic Cross spread?",  # ìŠ¤í”„ë ˆë“œ ì¿¼ë¦¬
        "Ace of Cups meaning in love",  # ì¹´ë“œ ì¿¼ë¦¬
        "Three card spread for relationships",  # ìŠ¤í”„ë ˆë“œ ì¿¼ë¦¬
        "Death card interpretation",  # ì¹´ë“œ ì¿¼ë¦¬
        "Past present future reading"  # ìŠ¤í”„ë ˆë“œ ì¿¼ë¦¬
    ]
    
    print("\nğŸ§ª TESTING TAROT RAG SYSTEM")
    print("=" * 80)
    
    for query in test_queries:
        print(f"\nğŸ” Query: {query}")
        
        # ìë™ ê²€ìƒ‰
        results = rag_system.search_auto(query, final_k=2, show_details=False)
        
        # ê²°ê³¼ ì¶œë ¥
        if results["cards"]:
            rag_system.pretty_print_results(results["cards"], "CARD")
        
        if results["spreads"]:
            rag_system.pretty_print_results(results["spreads"], "SPREAD")
        
        print("\n" + "-" * 80)
    
    # ì¹´ë“œ ì „ìš© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸƒ TESTING CARD-ONLY SEARCH")
    print("=" * 80)
    card_results = rag_system.search_cards("What does Strength card represent?", final_k=3, show_details=False)
    rag_system.pretty_print_results(card_results, "CARD")
    
    # ìŠ¤í”„ë ˆë“œ ì „ìš© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nğŸ”® TESTING SPREAD-ONLY SEARCH")
    print("=" * 80)
    spread_results = rag_system.search_spreads("chakra energy spread", final_k=3, show_details=False)
    rag_system.pretty_print_results(spread_results, "SPREAD")

if __name__ == "__main__":
    main()